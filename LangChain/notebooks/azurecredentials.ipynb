{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set environment variables in the .env file.\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_VERSION = os.environ[\"OPENAI_API_VERSION\"]\n",
    "OPENAI_API_BASE = os.environ[\"OPENAI_API_BASE\"]\n",
    "CHAT_DEPLOYMENT = os.environ[\"OPENAI_CHAT_DEPLOYMENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Use the current user identity to authenticate with Azure OpenAI, Cognitive Search and Blob Storage (no secrets needed, \n",
    "# just use 'az login' locally, and managed identity when deployed on Azure). If you need to use keys, use separate AzureKeyCredential instances with the \n",
    "# keys for each service\n",
    "# If you encounter an error here are some ways to troubleshoot:\n",
    "# - you can exclude the problematic credential by using a parameter (ex. exclude_shared_token_cache_credential=True)\n",
    "# - For your credential, grant Cognitive Services User and Cognitive Services OpenAI User roles - EVEN IF YOU HAVE OWNER/ADMIN RIGHTS.\n",
    "azure_credential = DefaultAzureCredential()\n",
    "ad_token = azure_credential.get_token(\"https://cognitiveservices.azure.com/.default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_type=\"azure_ad\",\n",
    "    openai_api_key=ad_token.token,\n",
    "    deployment_name=CHAT_DEPLOYMENT,\n",
    "    openai_api_version=OPENAI_API_VERSION,\n",
    "    max_tokens=100,\n",
    "    temperature=0.3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: How is Generative AI different from Machine Learning?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Generative AI is a subset of machine learning that focuses on creating new data rather than just analyzing existing data. While machine learning algorithms are trained on large datasets to make predictions or classifications, generative AI algorithms are designed to generate new data that is similar to the training data. This can be useful in a variety of applications, such as creating realistic images or generating natural language text. However, it can also be more complex and computationally intensive than traditional machine learning approaches.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"How is Generative AI different from Machine Learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How is Generative AI different from Machine Learning?\n",
      "AI: Generative AI is a subset of machine learning that focuses on creating new data rather than just analyzing existing data. While machine learning algorithms are trained on large datasets to make predictions or classifications, generative AI algorithms are designed to generate new data that is similar to the training data. This can be useful in a variety of applications, such as creating realistic images or generating natural language text. However, it can also be more complex and computationally intensive than traditional machine learning approaches.\n",
      "Human: how about deep learning?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Deep learning is a type of machine learning that uses neural networks with multiple layers to learn and make predictions. It is particularly effective for tasks that involve large amounts of data, such as image or speech recognition. Deep learning algorithms can automatically learn features from the data, which can lead to better performance compared to traditional machine learning approaches. However, deep learning models can be more complex and require more computational resources to train and deploy.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"how about deep learning?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
